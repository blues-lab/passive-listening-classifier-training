{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6222445964813232, 'start': 34, 'end': 95, 'answer': 'the task of extracting an answer from a text given a question'}\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"question-answering\")\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the `run_squad.py`.\n",
    "\"\"\"\n",
    "\n",
    "print(nlp(question=\"What is extractive question answering?\", context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res = pd.read_csv('weather_app_sample_convos.csv')  \n",
    "res = res[[\"Context\", \"Location\"]]\n",
    "res.dropna(inplace = True)\n",
    "res = res.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert strings to lower case\n",
    "res = res.applymap(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loc(questions=[\"where?\", \"what is the location?\", \"which area?\"]):\n",
    "    \"\"\"\n",
    "    Function to test qa model against a list of location related questions. \n",
    "    Calculates accuracy (disregards nan values)\n",
    "    \"\"\"\n",
    "    num_correct = []\n",
    "    for ques in questions:\n",
    "        curr_correct = 0\n",
    "        for index, row in res.iterrows():\n",
    "            context = row[\"Context\"]\n",
    "            nlp_res = nlp(question=ques, context=context)\n",
    "            \n",
    "            if nlp_res['answer'].lower() in str(row['Location']).lower(): \n",
    "                curr_correct += 1\n",
    "        num_correct.append(curr_correct/len(res))\n",
    "            \n",
    "    return num_correct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5945945945945946, 0.5135135135135135, 0.6216216216216216]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_1 = test_loc()\n",
    "accuracy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta-base-squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "nlp = pipeline(model=model_name, tokenizer=model_name, revision=\"v1.0\", task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5405405405405406, 0.4594594594594595, 0.35135135135135137]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_2 = test_loc()\n",
    "accuracy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert-small-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mrm8488/bert-small-finetuned-squadv2\"\n",
    "nlp = pipeline(model=model_name, tokenizer=model_name, task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5675675675675675, 0.5405405405405406, 0.5135135135135135]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3 = test_loc()\n",
    "accuracy_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert-tiny-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mrm8488/bert-tiny-5-finetuned-squadv2\"\n",
    "nlp = pipeline(model=model_name, tokenizer=model_name, task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5945945945945946, 0.5135135135135135, 0.6216216216216216]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_4 = test_loc()\n",
    "accuracy_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_pipeline</th>\n",
       "      <th>roberta_base_finetuned</th>\n",
       "      <th>bert_small_finetuned</th>\n",
       "      <th>bert_tiny_finetuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default_pipeline  roberta_base_finetuned  bert_small_finetuned  \\\n",
       "0          0.594595                0.540541              0.567568   \n",
       "1          0.513514                0.459459              0.540541   \n",
       "2          0.621622                0.351351              0.513514   \n",
       "\n",
       "   bert_tiny_finetuned  \n",
       "0             0.594595  \n",
       "1             0.513514  \n",
       "2             0.621622  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(columns = ['default_pipeline', 'roberta_base_finetuned', 'bert_small_finetuned', 'bert_tiny_finetuned'])\n",
    "accuracy_df['default_pipeline'] = accuracy_1\n",
    "accuracy_df['roberta_base_finetuned'] = accuracy_2\n",
    "accuracy_df['bert_small_finetuned'] = accuracy_3\n",
    "accuracy_df['bert_tiny_finetuned'] = accuracy_4\n",
    "\n",
    "accuracy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
