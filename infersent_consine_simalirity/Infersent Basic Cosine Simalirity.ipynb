{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dated-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import InferSent\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-spanish",
   "metadata": {},
   "source": [
    "### Note this does require downloading GloVe to some folder\n",
    "Download Glove via\n",
    "```sh\n",
    "mkdir GloVe\n",
    "curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "unzip GloVe/glove.840B.300d.zip -d GloVe/\n",
    "```\n",
    "and the encoders\n",
    "```sh\n",
    "mkdir encoder\n",
    "curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n",
    "```\n",
    "^Modify the Above for your operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "manual-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own path\n",
    "W2V_PATH = f\"GloVe/glove.840B.300d.txt\"\n",
    "model_version = 1\n",
    "MODEL_PATH = f'encoder/infersent%s.pkl' % model_version\n",
    "\n",
    "def generate_Infersent_model():\n",
    "    # Load model\n",
    "    params_model = {'bsize': 64, \n",
    "                    'word_emb_dim': 300, \n",
    "                    'enc_lstm_dim': 2048,\n",
    "                    'pool_type': 'max',\n",
    "                    'dpout_model': 0.0, \n",
    "                    'version': model_version}\n",
    "    model = InferSent(params_model)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "    model.set_w2v_path(W2V_PATH)\n",
    "\n",
    "    model.build_vocab_k_words(K=100000)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_doc2vec(text, model, verbose=False):\n",
    "    emb = model.encode(text, verbose=verbose)\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "northern-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "model = generate_Infersent_model()\n",
    "\n",
    "# Run the following if saved\n",
    "# PATH = (os.path.dirname(os.path.abspath(__file__))) + \"/\"\n",
    "# model = torch.load(PATH + \"infraset_model.torch\")\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "capable-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42611486"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "res = get_doc2vec([\"happy\", \"camper\"], model)\n",
    "cosine(res[0], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-reason",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-trinidad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-hudson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
